{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHiGwJ3qVoGP"
      },
      "source": [
        "## First install all required packages to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NztZXZoNVsu_",
        "outputId": "8458a120-1bb4-4603-bea5-fb248f8fc2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in /Users/mac/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /Users/mac/Library/Python/3.9/lib/python/site-packages (2.2.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/mac/Library/Python/3.9/lib/python/site-packages (1.4.2)\n",
            "Requirement already satisfied: torch in /Users/mac/Library/Python/3.9/lib/python/site-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /Users/mac/Library/Python/3.9/lib/python/site-packages (3.8.3)\n",
            "Requirement already satisfied: seaborn in /Users/mac/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
            "Requirement already satisfied: tensorflow in /Users/mac/Library/Python/3.9/lib/python/site-packages (2.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: networkx in /Users/mac/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: sympy in /Users/mac/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: fsspec in /Users/mac/Library/Python/3.9/lib/python/site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: filelock in /Users/mac/Library/Python/3.9/lib/python/site-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: pillow>=8 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.50.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: keras>=3.0.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
            "Requirement already satisfied: namex in /Users/mac/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
            "Requirement already satisfied: optree in /Users/mac/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: rich in /Users/mac/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/mac/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install numpy pandas scikit-learn torch matplotlib seaborn tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ60xVKcwBzs"
      },
      "source": [
        "## Define settings and model configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "fErL5G-SwKJ-"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"data\": [\n",
        "        'bug',\n",
        "        'feature',\n",
        "        'rating',\n",
        "        'user_experience'\n",
        "    ],\n",
        "    # Whether to combine all negative classes into one\n",
        "    'single_negative': False,\n",
        "    \"comment_type\": \n",
        "        #'stopwords',\n",
        "        #'stopwords_nltk',\n",
        "        #'stopwords_lemmatization',\n",
        "        #'lemmatization',\n",
        "        #'stemming',\n",
        "        \"comment\",\n",
        "    \"preprocess_steps\": [\n",
        "        \"special_characters\",\n",
        "        #\"remove_punctuation\",\n",
        "        #\"possessove_pronouns\",\n",
        "    ],\n",
        "    \"text_representation\": {\n",
        "        'method': 'tfidf',\n",
        "        'ngram_range': (1, 2),\n",
        "        'max_features': 500,\n",
        "        'max_df': 0.8,\n",
        "        'min_df': 0.01\n",
        "    },\n",
        "    \"randomForest\": {\n",
        "        \"param_grid\": {\n",
        "            # Hyper-parameter tuning for Random Forest\n",
        "            'n_estimators': [100, 300, 500],\n",
        "            'max_features': ['sqrt', 'log2'],\n",
        "            'max_depth': [20, 80, None],\n",
        "            'min_samples_split': [2, 5, 10]\n",
        "        },\n",
        "        \"search\": {\n",
        "            'method': 'grid',\n",
        "            'cv': 5,\n",
        "            'verbose': 2,\n",
        "            'n_jobs': -1,\n",
        "            'n_iter': 100\n",
        "        }\n",
        "\n",
        "    },\n",
        "    \"lstm\": {\n",
        "        \"vocab_size\": 5000,\n",
        "        \"embedding_dim\": 100,\n",
        "        \"hidden_size\": 64,\n",
        "        \"num_classes\": None,\n",
        "        \"dropout\": 0.3,\n",
        "        \"embedding_matrix\": None,\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I6aHwmddadW"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "hzZyXZDTdc3k"
      },
      "outputs": [],
      "source": [
        "data_paths = {\n",
        "  \"bug\": 'Bug_tt.json',\n",
        "  \"feature\": 'Feature_tt.json',\n",
        "  \"rating\": 'Rating_tt.json',\n",
        "  \"user_experience\": 'UserExperience_tt.json'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "cdPFWfl_pavq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "labels = []\n",
        "\n",
        "def load_data(params, cleaner):\n",
        "  X, y = [], []\n",
        "  for label in params[\"data\"]:\n",
        "    labels.append(label)\n",
        "    labels.append('not_' + label)\n",
        "    # Load data\n",
        "    with open(os.path.join('data', data_paths[label])) as f:\n",
        "      data_lst = json.load(f)\n",
        "      for data in data_lst:\n",
        "        X.append(cleaner.preprocess(data)) \n",
        "        y.append(data['label'])\n",
        "  return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fovztmxOW09O"
      },
      "source": [
        "### Preprocessing Steps\n",
        "1. Text Cleaning:\n",
        "  - Preprocessed Comment Selection:\n",
        "    1. stopwords_removal\n",
        "    2. stopwords_removal_nltk\n",
        "    3. stopwords_removal_lemmatization\n",
        "    4. lemmatized_comment\n",
        "    5. stemmed\n",
        "  - Other Proprocessing Steps:\n",
        "    1. remove_special_characters\n",
        "    2. remove_punctuation\n",
        "    3. remove_possessive_pronouns\n",
        "2. Label Encoding.\n",
        "3. Train-Test Split.\n",
        "4. Text Representation:\n",
        "  - TF-IDF.\n",
        "  - Word2Vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "cqPjiaE4SFA9"
      },
      "outputs": [],
      "source": [
        "# Text Cleaning\n",
        "import re\n",
        "import string\n",
        "\n",
        "class TextCleaner:\n",
        "  def __init__(self, settings):\n",
        "    self.settings = settings\n",
        "  \n",
        "  # Selection of pre-processed comments\n",
        "  def select_comment(self):\n",
        "    if self.commentType == 'stopwords': \n",
        "      self._remove_stopwords()\n",
        "    elif self.commentType == 'stopwords_nltk':\n",
        "      self._remove_stopwords_nltk()\n",
        "    elif self.commentType == 'stopwords_lemmatization':\n",
        "      self._removal_stopwords_lemmatization()\n",
        "    elif self.commentType == 'lemmatization':\n",
        "      self._lemmatization()\n",
        "    elif self.commentType == 'stemming':\n",
        "      self._stemming()\n",
        "    else:\n",
        "      self.X = self.data['comment']\n",
        "  \n",
        "  def _remove_stopwords(self):\n",
        "    self.X = self.data['stopwords_removal']\n",
        "\n",
        "  def _remove_stopwords_nltk(self):\n",
        "    self.X = self.data['stopwords_removal_nltk']\n",
        "\n",
        "  def _removal_stopwords_lemmatization(self):\n",
        "    self.X = self.data['stopwords_removal_lemmatization']\n",
        "\n",
        "  def _lemmatization(self):\n",
        "    self.X = self.data['lemmatized_comment']\n",
        "\n",
        "  def _stemming(self):\n",
        "    self.X = self.data['stemmed']\n",
        "\n",
        "  # Selection of pre-processed comments\n",
        "  def preprocess_comment(self):\n",
        "    if 'special_characters' in self.preprocess_steps:\n",
        "      self._remove_special_characters()\n",
        "    if 'remove_punctuation' in self.preprocess_steps:\n",
        "      self._remove_punctuation()\n",
        "    if 'possessove_pronouns' in self.preprocess_steps:\n",
        "      self._possessive_pronouns()\n",
        "\n",
        "  def _remove_special_characters(self):\n",
        "    pattern = r'[^a-zA-Z0-9\\s' + re.escape(string.punctuation) + r']'\n",
        "    self.X = re.sub(pattern, '', self.X)\n",
        "\n",
        "  def _remove_punctuation(self):\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    self.X = re.sub(pattern, '', self.X)\n",
        "  \n",
        "  def _possessive_pronouns(self):\n",
        "    pattern = r\"\\'s\\b|\\'m\\b|\\'are\\b\"\n",
        "    self.X = re.sub(pattern, '', self.X)\n",
        "\n",
        "  def preprocess(self, data):\n",
        "    self.data = data\n",
        "\n",
        "    self.commentType = self.settings['comment_type']\n",
        "    self.select_comment()\n",
        "  \n",
        "    self.preprocess_steps = self.settings['preprocess_steps']\n",
        "    self.preprocess_comment()\n",
        "    \n",
        "    return self.X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the TextCleaner based on params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "textCleaner = TextCleaner(params)\n",
        "X, y = load_data(params, textCleaner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Label Encode the y data (whether to combine all negative cases into one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "Xe_OQ-M4aKYY"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def label_encoding(y_data, single_negative=False):\n",
        "  label_encoder = LabelEncoder()\n",
        "  if single_negative:\n",
        "    # all label started with no_ will be considered as negative\n",
        "    y_data = ['negative' if 'no_' in label else label for label in y_data]\n",
        "  y_encoded = label_encoder.fit_transform(y_data)\n",
        "\n",
        "  return y_encoded\n",
        "\n",
        "y = label_encoding(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splitting data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "aOlO3lH1bNwd"
      },
      "outputs": [],
      "source": [
        "# Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(X, y, test_size=0.2, random_state=42):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                      test_size=test_size,\n",
        "                                                      random_state=random_state,\n",
        "                                                      stratify=y)\n",
        "  return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2268,) (568,) (2268,) (568,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = split_data(X, y)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the label distribution for all data\n",
        "def plot_label_distribution(y):\n",
        "    ax = sns.barplot(x=np.unique(y), y=pd.Series(y).value_counts().values)\n",
        "    plt.title('Label Distribution')\n",
        "    # label the bars\n",
        "    rects = ax.patches\n",
        "    for rect, label in zip(rects, labels):\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width()/2, height + 2, label, ha='center', va='bottom')\n",
        "    plt.show()\n",
        "\n",
        "plot_label_distribution(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Text Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "itr0XqHVb5nb"
      },
      "outputs": [],
      "source": [
        "# Text Representation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "class TextRepresenter:\n",
        "    def __init__(self, params):\n",
        "        self.settings = params['text_representation']\n",
        "        if self.settings['method'] == 'tfidf':\n",
        "            self.tfidf = TfidfVectorizer(encoding='utf-8',\n",
        "                                        ngram_range=self.settings['ngram_range'],\n",
        "                                        stop_words=None,\n",
        "                                        lowercase=False,\n",
        "                                        max_df=self.settings['max_df'],\n",
        "                                        min_df=self.settings['min_df'],\n",
        "                                        max_features=self.settings['max_features'],\n",
        "                                        norm='l2',\n",
        "                                        sublinear_tf=True)\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        return self.tfidf.fit_transform(X).toarray()               \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_representation = TextRepresenter(params)\n",
        "X_train_embed = text_representation.fit_transform(X_train)\n",
        "X_test_embed = text_representation.tfidf.transform(X_test).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3K9e0vYMvdN"
      },
      "source": [
        "## Define Traditional ML Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "I-HTcPbeM0P-"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, hamming_loss\n",
        "\n",
        "class TextRandomForest:\n",
        "  def __init__(self, params):\n",
        "    self.model = RandomForestClassifier()\n",
        "    self.param_grid = params[\"param_grid\"]\n",
        "\n",
        "    if params[\"search\"][\"method\"] == 'grid':\n",
        "      self.search_config = params[\"search\"]\n",
        "      self.model_selector = GridSearchCV(estimator=self.model,\n",
        "                                         param_grid=self.param_grid,\n",
        "                                         scoring={'accuracy': 'accuracy', 'f1_macro': 'f1_macro'},\n",
        "                                         refit='f1_macro',\n",
        "                                         cv=self.search_config[\"cv\"],\n",
        "                                         verbose=self.search_config[\"verbose\"],\n",
        "                                         n_jobs=self.search_config[\"n_jobs\"])\n",
        "    elif params[\"search\"][\"method\"] == 'random':\n",
        "      self.search_config = params[\"search\"]\n",
        "      self.model_selector = RandomizedSearchCV(estimator=self.model,\n",
        "                                               param_distributions=self.param_grid,\n",
        "                                               scoring={'accuracy': 'accuracy', 'f1_macro': 'f1_macro'},\n",
        "                                               refit='f1_macro',\n",
        "                                               n_iter=self.search_config[\"n_iter\"],\n",
        "                                               cv=self.search_config[\"cv\"],\n",
        "                                               verbose=self.search_config[\"verbose\"],\n",
        "                                               random_state=42,\n",
        "                                               n_jobs=self.search_config[\"n_jobs\"])\n",
        "    else:\n",
        "      raise ValueError(\"Search type must be either grid or random.\")\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    self.model_selector.fit(X_train, y_train)\n",
        "    self.best_estimator_ = self.model_selector.best_estimator_\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    return self.best_estimator_.predict(X_test)\n",
        "\n",
        "  def evaluate(self, X_test, y_test):\n",
        "    # Calculate various performance metrics\n",
        "    predictions = self.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions, average='macro')  # You can use other averages like 'micro', 'weighted'\n",
        "    recall = recall_score(y_test, predictions, average='macro')\n",
        "    f1 = f1_score(y_test, predictions, average='macro')\n",
        "    report = classification_report(y_test, predictions)\n",
        "\n",
        "    # Optional: Calculate Hamming Loss, useful for multi-label\n",
        "    ham_loss = hamming_loss(y_test, predictions)\n",
        "\n",
        "    # Print or return all the metrics\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"Hamming Loss: {ham_loss}\")\n",
        "    print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "    # You can choose to return these metrics in a dictionary if you prefer\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"hamming_loss\": ham_loss,\n",
        "        \"classification_report\": report\n",
        "    }\n",
        "\n",
        "  def best_params(self):\n",
        "    return self.model_selector.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   1.9s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   2.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   2.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   2.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   1.6s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   1.8s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   1.8s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   0.8s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   0.8s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   0.8s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   0.7s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=300; total time=   0.8s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   1.6s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   1.8s\n",
            "[CV] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.7s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.7s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.6s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.6s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.6s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.6s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.6s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.6s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.5s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=500; total time=   0.9s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.0s\n",
            "[CV] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   1.9s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.0s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=80, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.8s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.5s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.6s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.4s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.4s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=80, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.2s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.4s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.6s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.6s\n",
            "[CV] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.1s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.2s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.8s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.8s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=500; total time=   1.9s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.8s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=300; total time=   0.9s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.3s\n",
            "[CV] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=500; total time=   1.3s\n",
            "Accuracy: 0.18485915492957747\n",
            "Precision: 0.15617372042983238\n",
            "Recall: 0.18130659995066775\n",
            "F1 Score: 0.16558900074137947\n",
            "Hamming Loss: 0.8151408450704225\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.39      0.36        74\n",
            "           1       0.13      0.12      0.12        59\n",
            "           2       0.00      0.00      0.00        74\n",
            "           3       0.09      0.06      0.07        65\n",
            "           4       0.04      0.04      0.04        74\n",
            "           5       0.18      0.16      0.17        74\n",
            "           6       0.20      0.32      0.24        74\n",
            "           7       0.28      0.35      0.31        74\n",
            "\n",
            "    accuracy                           0.18       568\n",
            "   macro avg       0.16      0.18      0.17       568\n",
            "weighted avg       0.16      0.18      0.17       568\n",
            "\n",
            "{'accuracy': 0.18485915492957747, 'precision': 0.15617372042983238, 'recall': 0.18130659995066775, 'f1_score': 0.16558900074137947, 'hamming_loss': 0.8151408450704225, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       0.33      0.39      0.36        74\\n           1       0.13      0.12      0.12        59\\n           2       0.00      0.00      0.00        74\\n           3       0.09      0.06      0.07        65\\n           4       0.04      0.04      0.04        74\\n           5       0.18      0.16      0.17        74\\n           6       0.20      0.32      0.24        74\\n           7       0.28      0.35      0.31        74\\n\\n    accuracy                           0.18       568\\n   macro avg       0.16      0.18      0.17       568\\nweighted avg       0.16      0.18      0.17       568\\n'}\n"
          ]
        }
      ],
      "source": [
        "# Train Random Forest\n",
        "random_forest = TextRandomForest(params[\"randomForest\"])\n",
        "random_forest.fit(X_train_embed, y_train)\n",
        "result = random_forest.evaluate(X_test_embed, y_test)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KadwQEdaWbmB"
      },
      "source": [
        "## Define CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "Rxi2xNJHWqcR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "  def __init__(self, params):\n",
        "    super(TextCNN, self).__init__()\n",
        "    import pdb; pdb.set_trace()\n",
        "    self.embedding = nn.Embedding(params[\"vocab_size\"], params[\"embed_size\"])\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(params[\"embedding_matrix\"],\n",
        "                                                      dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = True\n",
        "\n",
        "    self.convs = nn.ModuleList([nn.Conv2d(1, params[\"num_filters\"],\n",
        "                               (K, params[\"embed_size\"]))\n",
        "                               for K in params[\"filter_sizes\"]])\n",
        "    self.relu = nn.ReLu()\n",
        "    self.maxpool = n.MaxPool1d()\n",
        "    self.dropout = nn.Dropout(params[\"dropout\"])\n",
        "    self.fc = nn.Linear(len(params[\"filter_sizes\"]) * params[\"num_filters\"],\n",
        "                        params[\"num_classes\"])\n",
        "\n",
        "  def forward(self, X):\n",
        "    X_embedding = self.embedding(X)\n",
        "    X = X_embedding.unsqueeze(1)\n",
        "    X = [self.relu(conv(X)).squeeze(3) for conv in self.convs]\n",
        "    X = [self.maxpool1d(x, x.size(2)).squeeze(2) for x in X]\n",
        "    X = torch.cat(X, 1)\n",
        "    X = self.dropout(X)\n",
        "    return self.fc(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66jeYtFpb6nW"
      },
      "source": [
        "## Define LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "nncV435GbjYL"
      },
      "outputs": [],
      "source": [
        "class TextLSTM(nn.Module):\n",
        "  def __init__(self, params):\n",
        "    super(TextLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = params[\"hidden_size\"]\n",
        "    # Embedding layer tooks two arguments: vocab_size and embedding_dim\n",
        "    self.embedding = nn.Embedding(params[\"vocab_size\"], params[\"embedding_dim\"])#,\n",
        "                                  #input_length=params[\"max_length\"])\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(params[\"embedding_matrix\"],\n",
        "                                                      dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = True\n",
        "\n",
        "    self.lstm = nn.LSTM(params[\"embedding_dim\"], self.hidden_size,\n",
        "                        bidirectional=True, batch_first=True)\n",
        "    self.linear = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(params[\"dropout\"])\n",
        "    self.fc = nn.Linear(self.hidden_size, params['num_classes'])\n",
        "\n",
        "  def forward(self, X):\n",
        "    print(\"Input X shape:\", X.shape)\n",
        "    X = self.embedding(X)\n",
        "    print(\"After embedding:\", X.shape)\n",
        "    X, _ = self.lstm(X)\n",
        "    print(\"After LSTM:\", X.shape)\n",
        "    # Assuming the LSTM is bidirectional and you want to concatenate the last forward and first backward states\n",
        "    X = torch.cat((X[:, -1, :self.hidden_size], X[:, 0, self.hidden_size:]), dim=1)\n",
        "\n",
        "    print(\"After concat:\", X.shape)\n",
        "    X = self.linear(X)\n",
        "    print(\"After first linear layer:\", X.shape)\n",
        "    X = self.relu(X)\n",
        "    X = self.dropout(X)\n",
        "    X = self.fc(X)\n",
        "    print(\"Final output:\", X.shape)\n",
        "    return X\n",
        "\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 500\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "# Fit the tokenizer on the training data\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "max_len = max([len(x) for x in X_train_seq])\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "\n",
        "# Fit the tokenizer on the test data\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_params = params[\"lstm\"]\n",
        "lstm_params[\"num_classes\"] = len(np.unique(y))\n",
        "\n",
        "# vocab_size is the number of unique words in your dataset and embedding_dim is the dimension of the word vectors\n",
        "lstm_params[\"embedding_dim\"] = X_train_embed.shape[1]\n",
        "lstm_params[\"vocab_size\"] = vocab_size\n",
        "lstm_params[\"embedding_matrix\"] = X_train_embed\n",
        "lstm_params[\"max_length\"] = max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input X shape: torch.Size([2268, 593])\n",
            "After embedding: torch.Size([2268, 593, 472])\n",
            "After LSTM: torch.Size([2268, 593, 128])\n",
            "After concat: torch.Size([2268, 128])\n",
            "After first linear layer: torch.Size([2268, 64])\n",
            "Final output: torch.Size([2268, 8])\n",
            "Input X shape: torch.Size([568, 593])\n",
            "After embedding: torch.Size([568, 593, 472])\n",
            "After LSTM: torch.Size([568, 593, 128])\n",
            "After concat: torch.Size([568, 128])\n",
            "After first linear layer: torch.Size([568, 64])\n",
            "Final output: torch.Size([568, 8])\n",
            "Accuracy: 0.13028169014084506\n",
            "Recall: 0.125\n",
            "F1 Score: 0.02881619937694704\n"
          ]
        }
      ],
      "source": [
        "lstm = TextLSTM(lstm_params)\n",
        "lstm.forward(torch.tensor(X_train_pad))\n",
        "# evaluate model\n",
        "lstm.eval()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "with torch.no_grad():\n",
        "    output = lstm(torch.tensor(X_test_pad))\n",
        "    loss = criterion(output, torch.tensor(y_test))\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    accuracy = (predicted == torch.tensor(y_test)).sum().item() / len(y_test)\n",
        "    recall = recall_score(y_test, predicted, average='macro')\n",
        "    f1 = f1_score(y_test, predicted, average='macro')\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Useful links: https://medium.com/analytics-vidhya/an-introduction-to-multi-label-text-classification-b1bcb7c7364c"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
